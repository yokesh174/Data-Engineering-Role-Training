{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install PySpark\n",
        "We first need to install **PySpark** in Google Colab because it is not available by default.  \n",
        "The command below will install the latest version of PySpark using `pip`.\n"
      ],
      "metadata": {
        "id": "JqrVSUJXO0ed"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WfYqVSL3wUU",
        "outputId": "b177d972-3753-4719-c29a-0163d657ff76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a SparkSession\n",
        "To use PySpark, we need to create a **SparkSession**.  \n",
        "- `SparkSession` is the entry point to programming with Spark in Python.  \n",
        "- Here, we set an application name as `\"Colab-PySpark-Basics\"`.  \n",
        "- After creating the session, we print the current **Apache Spark version** to confirm everything is set up correctly.\n"
      ],
      "metadata": {
        "id": "JdnRs7J7O4Y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Colab-PySpark-Basics\").getOrCreate()\n",
        "print(\"Apache Spark Vesrion:\",spark.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKoK55iS6sMx",
        "outputId": "ed050380-a91e-4551-bffe-f7ddb34761b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apache Spark Vesrion: 3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Sample DataFrame\n",
        "Now we will create a simple **DataFrame** in PySpark.  \n",
        "\n",
        "1. Define some **sample data** as a list of tuples.  \n",
        "   - Example: `(\"Rahul\", 21)` represents a row.  \n",
        "2. Define the **schema** (column names) → `[\"Name\", \"Age\"]`.  \n",
        "3. Use `spark.createDataFrame(data, columns)` to create the DataFrame.  \n",
        "4. Finally, use `df.show()` to display the DataFrame in a tabular format.\n"
      ],
      "metadata": {
        "id": "nnMw28bePE8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "\n",
        "data = [(\"Rahul\", 21), (\"Priya\", 22), (\"Aman\", 20)]\n",
        "\n",
        "# Define schema (columns)\n",
        "\n",
        "columns = [\"Name\", \"Age\"]\n",
        "\n",
        "# Create DataFrame\n",
        "\n",
        "df = spark.createDataFrame (data, columns)\n",
        "\n",
        "# Show DataFrame\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXSQnf1O9M5R",
        "outputId": "20fbcd8a-d881-466d-f01a-9b11f68a6ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|Rahul| 21|\n",
            "|Priya| 22|\n",
            "| Aman| 20|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic DataFrame Operations\n",
        "Let’s perform some common operations on the DataFrame:\n",
        "\n",
        "1. **Select a column** → `df.select(\"Name\").show()`  \n",
        "   - Displays only the `Name` column.  \n",
        "\n",
        "2. **Filter rows** → `df.filter(df[\"Age\"] > 20).show()`  \n",
        "   - Returns only the rows where `Age` is greater than 20.  \n",
        "\n",
        "3. **Count rows** → `df.count()`  \n",
        "   - Returns the total number of rows in the DataFrame.\n"
      ],
      "metadata": {
        "id": "y6ycmc9GPOMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select column\n",
        "\n",
        "df.select(\"Name\").show()\n",
        "\n",
        "# Filter rows\n",
        "\n",
        "df.filter(df[\"Age\"] > 20).show()\n",
        "\n",
        "# Count rows\n",
        "\n",
        "print(\"Total rows:\", df.count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vHAzkPfBLft",
        "outputId": "65843104-3a60-4f34-fbe6-f37608ed8b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "| Name|\n",
            "+-----+\n",
            "|Rahul|\n",
            "|Priya|\n",
            "| Aman|\n",
            "+-----+\n",
            "\n",
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|Rahul| 21|\n",
            "|Priya| 22|\n",
            "+-----+---+\n",
            "\n",
            "Total rows: <bound method DataFrame.count of DataFrame[Name: string, Age: bigint]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X6VmEyiHBTmr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}