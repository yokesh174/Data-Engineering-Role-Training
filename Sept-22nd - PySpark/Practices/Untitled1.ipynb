{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Working with CSV Data in Python\n",
        "Now let’s see how to read and process **CSV data** using Python’s built-in `csv` module:\n",
        "\n",
        "1. **Create CSV data as a string**  \n",
        "   - Instead of reading from a file, we store CSV data in a multiline string.  \n",
        "\n",
        "2. **Use `StringIO` to treat string like a file**  \n",
        "   - `io.StringIO(csv_data)` allows us to use the string as if it were a file object.  \n",
        "\n",
        "3. **Read CSV using `DictReader`**  \n",
        "   - `csv.DictReader(file_like)` reads each row as a dictionary where column names are keys.  \n",
        "\n",
        "4. **Process the records**  \n",
        "   - Loop through each row, strip extra spaces from keys, and print in a formatted way.\n"
      ],
      "metadata": {
        "id": "ZMZHNpsXQWhG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2TkH6ueCyiM",
        "outputId": "b8c99992-40ae-4c2c-9c5f-47f4dec03494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Employee Records:\n",
            "1 -  Rahul Sharma ( IT)  55000\n",
            "2 -  Priya Singh ( HR)  60000\n",
            "3 -  Aman Kumar ( Finance)  48000\n",
            "4 -  Sneha Reddy ( Marketing)  52 52000\n",
            "5 -  Arjun Mehta ( IT)  75000\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import io\n",
        "\n",
        "# Step 1: Create CSV data as a string\n",
        "csv_data = \"\"\"id, name, department, salary\n",
        "1, Rahul Sharma, IT, 55000\n",
        "2, Priya Singh, HR, 60000\n",
        "3, Aman Kumar, Finance, 48000\n",
        "4, Sneha Reddy, Marketing, 52 52000\n",
        "5, Arjun Mehta, IT, 75000\"\"\"\n",
        "\n",
        "# Step 2: Use String10 to treat string like a file\n",
        "file_like = io.StringIO(csv_data)\n",
        "\n",
        "# Step 3: Read CSV using DictReader reader csv.DictReader(file_like)\n",
        "reader = csv.DictReader(file_like)\n",
        "\n",
        "print(\"Employee Records:\")\n",
        "\n",
        "for row in reader:\n",
        "    # Remove leading and trailing spaces from keys\n",
        "    row = {k.strip(): v for k, v in row.items()}\n",
        "    print(f\"{row['id']} - {row['name']} ({row['department']}) {row['salary']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install and Initialize PySpark\n",
        "1. **Install PySpark**  \n",
        "   - Since Google Colab does not come with PySpark pre-installed, we use `!pip install pyspark`.  \n",
        "\n",
        "2. **Create a SparkSession**  \n",
        "   - `SparkSession` is the entry point for PySpark applications.  \n",
        "   - Here, we set the app name as `\"Employee.Analysis\"`.  \n",
        "   - Once created, we can use `spark` to work with DataFrames and SQL queries.\n"
      ],
      "metadata": {
        "id": "wK9aEASBQZ7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Employee.Analysis\").getOrCreate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAZeh1p7qhQ0",
        "outputId": "4ea6cb8a-019a-4201-8e44-abc896d06c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a CSV File in Colab\n",
        "Instead of uploading a file manually, we can **create a CSV file directly in Colab**:\n",
        "\n",
        "1. Define the CSV data as a **multiline string**.  \n",
        "   - Each row contains `id, name, department, salary`.  \n",
        "\n",
        "2. Use Python’s `open()` in **write mode (\"w\")**.  \n",
        "   - This creates a new file named `employees.csv` in the current working directory.  \n",
        "\n",
        "3. Write the CSV string into the file using `f.write(csv_data)`.  \n",
        "\n",
        "After this step, we will have an actual file (`employees.csv`) stored in Colab that can be read using PySpark or Pandas.\n"
      ],
      "metadata": {
        "id": "kcw0QLaJQi1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "\n",
        "csv_data = \"\"\"id,name,department,salary\n",
        "1,Rahul Sharma,IT,55000\n",
        "2,Priya Singh,HR,60000\n",
        "3,Aman Kumar,Finance,48000\n",
        "4,Sneha Reddy,Marketing,52000\n",
        "5,Arjun Mehta,IT,75000\n",
        "6,Divya Nair,Finance,67000\n",
        "\"\"\"\n",
        "\n",
        "with open (\"employees.csv\", \"w\") as f:\n",
        "    f.write(csv_data)"
      ],
      "metadata": {
        "id": "BtC-kCutp_Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load CSV into PySpark DataFrame\n",
        "Now we will **read the CSV file we created** into a PySpark DataFrame:\n",
        "\n",
        "1. `spark.read.csv(\"employees.csv\", header=True, inferSchema=True)`  \n",
        "   - `header=True` → Treat the first row as column names.  \n",
        "   - `inferSchema=True` → Automatically detect the data type of each column.  \n",
        "\n",
        "2. `df.show()` → Display the contents of the DataFrame in a tabular format.\n"
      ],
      "metadata": {
        "id": "227nWv99QrCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"employees.csv\", header=True, inferSchema=True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZnYs3BLqA9p",
        "outputId": "e13b94e0-71a9-4d8a-bfcb-f81f642af89d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+----------+------+\n",
            "| id|        name|department|salary|\n",
            "+---+------------+----------+------+\n",
            "|  1|Rahul Sharma|        IT| 55000|\n",
            "|  2| Priya Singh|        HR| 60000|\n",
            "|  3|  Aman Kumar|   Finance| 48000|\n",
            "|  4| Sneha Reddy| Marketing| 52000|\n",
            "|  5| Arjun Mehta|        IT| 75000|\n",
            "|  6|  Divya Nair|   Finance| 67000|\n",
            "+---+------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 📝 Key Points about Transformations\n",
        "\n",
        "* **Lazy Execution**:\n",
        "\n",
        "  Spark doesn’t run transformations right away. Instead, it builds a **logical plan** (a DAG – Directed Acyclic Graph).\n",
        "\n",
        "  The computation only runs when an **action** (like `.show()` or `.count()`) is called.\n",
        "\n",
        "* **Return Type**:\n",
        "\n",
        "  A transformation always returns a **new DataFrame or RDD**. It does **not modify the existing one**.\n",
        "\n",
        "* **Two Types of Transformations**:\n",
        "\n",
        "  1. **Narrow Transformations** → Each input partition contributes to only one output partition.\n",
        "\n",
        "     (e.g., `map()`, `filter()`, `select()`)\n",
        "\n",
        "  2. **Wide Transformations** → Data is shuffled across partitions.\n",
        "\n",
        "     (e.g., `groupBy()`, `join()`)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "vQbZVuM6x7Pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select name & salary\n",
        "df.select(\"name\", \"salary\").show()\n",
        "#Filter employees with salary > 60,000\n",
        "df.filter(df[\"salary\"] > 60000).show()\n",
        "# Order by salary descending\n",
        "df.orderBy(df[\"salary\"].desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me5BK1rkyXJj",
        "outputId": "9fcc8e59-5d31-4fc3-bc87-74ba05e017f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------+\n",
            "|        name|salary|\n",
            "+------------+------+\n",
            "|Rahul Sharma| 55000|\n",
            "| Priya Singh| 60000|\n",
            "|  Aman Kumar| 48000|\n",
            "| Sneha Reddy| 52000|\n",
            "| Arjun Mehta| 75000|\n",
            "|  Divya Nair| 67000|\n",
            "+------------+------+\n",
            "\n",
            "+---+-----------+----------+------+\n",
            "| id|       name|department|salary|\n",
            "+---+-----------+----------+------+\n",
            "|  5|Arjun Mehta|        IT| 75000|\n",
            "|  6| Divya Nair|   Finance| 67000|\n",
            "+---+-----------+----------+------+\n",
            "\n",
            "+---+------------+----------+------+\n",
            "| id|        name|department|salary|\n",
            "+---+------------+----------+------+\n",
            "|  5| Arjun Mehta|        IT| 75000|\n",
            "|  6|  Divya Nair|   Finance| 67000|\n",
            "|  2| Priya Singh|        HR| 60000|\n",
            "|  1|Rahul Sharma|        IT| 55000|\n",
            "|  4| Sneha Reddy| Marketing| 52000|\n",
            "|  3|  Aman Kumar|   Finance| 48000|\n",
            "+---+------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 📝 What is Aggregation?\n",
        "\n",
        "* An operation that **groups data** and applies a **summary function** (like sum, avg, count, min, max).\n",
        "\n",
        "* Used to answer questions like:\n",
        "\n",
        "  * *“What is the average salary per department?”*\n",
        "\n",
        "  * *“How many employees are in each department?”*\n",
        "\n",
        "  * *“What is the highest salary in Finance?”*\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "NQ0I0Dyv5E9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Average salary per department\n",
        "df.groupBy(\"department\").avg(\"salary\").show()\n",
        "#Maximum salary per department\n",
        "df.groupBy(\"department\").max(\"salary\").show()\n",
        "#Count employees per department\n",
        "df.groupBy(\"department\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQQPKq965G18",
        "outputId": "5d6ef4f8-6ce9-4889-b422-eebce168b3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|department|avg(salary)|\n",
            "+----------+-----------+\n",
            "|        HR|    60000.0|\n",
            "|   Finance|    57500.0|\n",
            "| Marketing|    52000.0|\n",
            "|        IT|    65000.0|\n",
            "+----------+-----------+\n",
            "\n",
            "+----------+-----------+\n",
            "|department|max(salary)|\n",
            "+----------+-----------+\n",
            "|        HR|      60000|\n",
            "|   Finance|      67000|\n",
            "| Marketing|      52000|\n",
            "|        IT|      75000|\n",
            "+----------+-----------+\n",
            "\n",
            "+----------+-----+\n",
            "|department|count|\n",
            "+----------+-----+\n",
            "|        HR|    1|\n",
            "|   Finance|    2|\n",
            "| Marketing|    1|\n",
            "|        IT|    2|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SQL Queries on PySpark DataFrame\n",
        "PySpark allows us to run **SQL queries** on DataFrames by creating a temporary view:\n",
        "\n",
        "1. `df.createOrReplaceTempView(\"employees\")`  \n",
        "   - Creates a **temporary view** named `\"employees\"` that we can query using SQL syntax.  \n",
        "\n",
        "2. Run an **SQL query**:  \n",
        "   ```sql\n",
        "   SELECT department, AVG(salary) as avg_salary\n",
        "   FROM employees\n",
        "   GROUP BY department\n"
      ],
      "metadata": {
        "id": "FO79Kk71Q2k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"employees\")\n",
        "\n",
        "spark.sql(\"SELECT department, AVG(salary) as avg_salary FROM employees GROUP BY department\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_LH_Sbq9_yL",
        "outputId": "0eebc291-89c8-4849-eb6e-42fdd51e48d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|department|avg_salary|\n",
            "+----------+----------+\n",
            "|        HR|   60000.0|\n",
            "|   Finance|   57500.0|\n",
            "| Marketing|   52000.0|\n",
            "|        IT|   65000.0|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}