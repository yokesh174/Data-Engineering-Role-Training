{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Spark Session & Context\n",
        "\n",
        "- **SparkSession**: Entry point to use DataFrames and SQL in PySpark.  \n",
        "- **SparkContext**: Core connection to the Spark cluster, used for creating RDDs.  \n"
      ],
      "metadata": {
        "id": "Y7V1owuOaG88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AVO6q0SuYRf7"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"RDD-Exercises-Set2\").getOrCreate()\n",
        "sc = spark.sparkContext\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -------------------- 1. Numbers Practice --------------------\n"
      ],
      "metadata": {
        "id": "4bpkd4NSbp_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RDD Operations Example\n",
        "\n",
        "- **Divisible by 3**  \n",
        "  Filters numbers that are multiples of 3.  \n",
        "\n",
        "- **Doubled Values**  \n",
        "  Maps each number to its double.  \n",
        "\n",
        "- **Count Greater Than 10**  \n",
        "  Counts how many numbers are greater than 10.  \n"
      ],
      "metadata": {
        "id": "WRbYRxUUaKrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nums = sc.parallelize(range(1, 16))\n",
        "div_by_3 = nums.filter(lambda x: x % 3 == 0).collect()\n",
        "doubled = nums.map(lambda x: x * 2).collect()\n",
        "count_gt_10 = nums.filter(lambda x: x > 10).count()\n",
        "\n",
        "print(\"Divisible by 3:\", div_by_3)\n",
        "print(\"Doubled:\", doubled)\n",
        "print(\"Count > 10:\", count_gt_10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMMz72zXYwGL",
        "outputId": "6f9c5843-d738-44d0-8d4e-c0d90840a3e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Divisible by 3: [3, 6, 9, 12, 15]\n",
            "Doubled: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]\n",
            "Count > 10: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -------------------- 2. String Processing --------------------\n"
      ],
      "metadata": {
        "id": "QwPsrBUmb3Uj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RDD Operations with Fruits\n",
        "\n",
        "- **Distinct Fruits**  \n",
        "  Removes duplicates and returns unique fruit names.  \n",
        "\n",
        "- **Fruit Counts**  \n",
        "  Counts how many times each fruit appears using `map` and `reduceByKey`.  \n",
        "\n",
        "- **Longest Fruit**  \n",
        "  Finds the fruit name with the maximum length.  \n"
      ],
      "metadata": {
        "id": "dD0kD6fxaVYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fruits = sc.parallelize([\"apple\", \"banana\", \"grape\", \"banana\", \"apple\", \"mango\"])\n",
        "distinct_fruits = fruits.distinct().collect()\n",
        "fruit_counts = fruits.map(lambda x: (x, 1)).reduceByKey(lambda a, b: a + b).collect()\n",
        "longest_fruit = fruits.reduce(lambda a, b: a if len(a) > len(b) else b)\n",
        "\n",
        "print(\"Distinct Fruits:\", distinct_fruits)\n",
        "print(\"Fruit Counts:\", fruit_counts)\n",
        "print(\"Longest Fruit:\", longest_fruit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZBNWO4uZBI8",
        "outputId": "2cd62d9f-94f2-471b-9c40-1f69a71ea9e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distinct Fruits: ['apple', 'banana', 'grape', 'mango']\n",
            "Fruit Counts: [('apple', 2), ('banana', 2), ('grape', 1), ('mango', 1)]\n",
            "Longest Fruit: banana\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -------------------- 3. Sentence Split --------------------\n"
      ],
      "metadata": {
        "id": "TRvwW6mHb6AX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RDD Operations with Sentences\n",
        "\n",
        "- **Split into Words**  \n",
        "  Uses `flatMap` to split each sentence into words and convert them to lowercase.  \n",
        "\n",
        "- **Unique Words**  \n",
        "  Finds distinct words across all sentences.  \n",
        "\n",
        "- **Unique Word Count**  \n",
        "  Counts the total number of unique words.  \n"
      ],
      "metadata": {
        "id": "Q3eNnaIIah8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sc.parallelize([\n",
        "    \"spark makes big data easy\",\n",
        "    \"rdd is the core of spark\",\n",
        "    \"python with spark\"\n",
        "])\n",
        "words = sentences.flatMap(lambda s: s.split(\" \")).map(lambda w: w.lower())\n",
        "unique_words = words.distinct().collect()\n",
        "unique_word_count = words.distinct().count()\n",
        "\n",
        "print(\"Unique Words:\", unique_words)\n",
        "print(\"Unique Word Count:\", unique_word_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx9arM_EZLAb",
        "outputId": "7a751cd1-1671-4480-f719-2655e06355d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Words: ['big', 'easy', 'rdd', 'core', 'of', 'python', 'with', 'spark', 'makes', 'data', 'is', 'the']\n",
            "Unique Word Count: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -------------------- 4. Pair RDD Operations --------------------\n"
      ],
      "metadata": {
        "id": "la8t3lJSb-10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RDD Operations with Student Marks\n",
        "\n",
        "- **Total Marks**  \n",
        "  Adds up marks for each student using `reduceByKey`.  \n",
        "\n",
        "- **Average Marks**  \n",
        "  Calculates average marks per student by summing marks and counts, then dividing.  \n",
        "\n",
        "- **Highest Marks**  \n",
        "  Finds the student with the maximum single score.  \n"
      ],
      "metadata": {
        "id": "LlCLFhzNa11U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "marks = sc.parallelize([\n",
        "    (\"Rahul\", 85), (\"Priya\", 92), (\"Aman\", 78), (\"Rahul\", 90), (\"Priya\", 88)\n",
        "])\n",
        "total_marks = marks.reduceByKey(lambda a, b: a + b).collect()\n",
        "avg_marks = marks.mapValues(lambda x: (x, 1)) \\\n",
        "                 .reduceByKey(lambda a, b: (a[0]+b[0], a[1]+b[1])) \\\n",
        "                 .mapValues(lambda x: x[0]/x[1]).collect()\n",
        "highest = marks.reduce(lambda a, b: a if a[1] > b[1] else b)\n",
        "\n",
        "print(\"Total Marks:\", total_marks)\n",
        "print(\"Average Marks:\", avg_marks)\n",
        "print(\"Highest Marks:\", highest)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b1X9Dj-ZUOK",
        "outputId": "6289f24e-bbc6-43de-b0cf-eca7fbdb3499"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Marks: [('Rahul', 175), ('Priya', 180), ('Aman', 78)]\n",
            "Average Marks: [('Rahul', 87.5), ('Priya', 90.0), ('Aman', 78.0)]\n",
            "Highest Marks: ('Priya', 92)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -------------------- 5. Reduce & Aggregate --------------------\n"
      ],
      "metadata": {
        "id": "m160gfBncE9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RDD Operations with Numbers\n",
        "\n",
        "- **Sum**  \n",
        "  Adds all numbers using `reduce`.  \n",
        "\n",
        "- **Product**  \n",
        "  Multiplies all numbers using `reduce`.  \n",
        "\n",
        "- **Average**  \n",
        "  Divides the total sum by the count of numbers.  \n"
      ],
      "metadata": {
        "id": "i2R_p2N9a9CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nums2 = sc.parallelize([5, 10, 15, 20, 25])\n",
        "sum_val = nums2.reduce(lambda a, b: a + b)\n",
        "product_val = nums2.reduce(lambda a, b: a * b)\n",
        "count_val = nums2.count()\n",
        "avg_val = sum_val / count_val\n",
        "\n",
        "print(\"Sum:\", sum_val)\n",
        "print(\"Product:\", product_val)\n",
        "print(\"Average:\", avg_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcUtAwFwZYzC",
        "outputId": "d8135395-8800-460a-ec9d-4bb0cdbcfdd0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum: 75\n",
            "Product: 375000\n",
            "Average: 15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -------------------- 6. Word Length Analysis --------------------\n"
      ],
      "metadata": {
        "id": "IN2y7p15cJd1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RDD Operations with Words\n",
        "\n",
        "- **Word Lengths**  \n",
        "  Maps each word to a tuple of (word, length).  \n",
        "\n",
        "- **Longest Word**  \n",
        "  Finds the word with the maximum length using `reduce`.  \n",
        "\n",
        "- **Average Length**  \n",
        "  Calculates the average length of all words.\n"
      ],
      "metadata": {
        "id": "q5NWntX0bG8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words2 = sc.parallelize([\"data\", \"engineering\", \"spark\", \"rdd\", \"pyspark\", \"analytics\"])\n",
        "word_lengths = words2.map(lambda w: (w, len(w))).collect()\n",
        "longest_word = words2.reduce(lambda a, b: a if len(a) > len(b) else b)\n",
        "avg_length = words2.map(lambda w: len(w)).sum() / words2.count()\n",
        "\n",
        "print(\"Word Lengths:\", word_lengths)\n",
        "print(\"Longest Word:\", longest_word)\n",
        "print(\"Average Length:\", avg_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHG88tqiZc7M",
        "outputId": "c418069a-8fa6-41be-f095-391c889d4ab2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Lengths: [('data', 4), ('engineering', 11), ('spark', 5), ('rdd', 3), ('pyspark', 7), ('analytics', 9)]\n",
            "Longest Word: engineering\n",
            "Average Length: 6.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -------------------- 7. Joins --------------------\n"
      ],
      "metadata": {
        "id": "usbX7wZucMjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RDD Joins\n",
        "\n",
        "- **Inner Join**  \n",
        "  Returns only the students who have a matching course ID.  \n",
        "\n",
        "- **Left Outer Join**  \n",
        "  Returns all students and their courses if available; `None` if no matching course.  \n",
        "\n",
        "- **Right Outer Join**  \n",
        "  Returns all courses and the students enrolled if available; `None` if no matching student.\n"
      ],
      "metadata": {
        "id": "XA7-2yRWbXOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "students = sc.parallelize([(1, \"Rahul\"), (2, \"Priya\"), (3, \"Aman\")])\n",
        "courses = sc.parallelize([(1, \"Python\"), (2, \"Spark\"), (4, \"Databases\")])\n",
        "\n",
        "inner_join = students.join(courses).collect()\n",
        "left_join = students.leftOuterJoin(courses).collect()\n",
        "right_join = students.rightOuterJoin(courses).collect()\n",
        "\n",
        "print(\"Inner Join:\", inner_join)\n",
        "print(\"Left Outer Join:\", left_join)\n",
        "print(\"Right Outer Join:\", right_join)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu5suRRMZgsa",
        "outputId": "0375e7d3-434d-4c28-e82a-c7c52f71596e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inner Join: [(1, ('Rahul', 'Python')), (2, ('Priya', 'Spark'))]\n",
            "Left Outer Join: [(1, ('Rahul', 'Python')), (2, ('Priya', 'Spark')), (3, ('Aman', None))]\n",
            "Right Outer Join: [(4, (None, 'Databases')), (1, ('Rahul', 'Python')), (2, ('Priya', 'Spark'))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -------------------- 8. Mini Real-World --------------------\n"
      ],
      "metadata": {
        "id": "gFtfyqrycTws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RDD Operations with Orders\n",
        "\n",
        "- **Total per Customer**  \n",
        "  Sums all order amounts for each customer using `reduceByKey`.  \n",
        "\n",
        "- **Customer with Maximum Spend**  \n",
        "  Finds the customer who spent the most.  \n",
        "\n",
        "- **Total Revenue**  \n",
        "  Calculates the sum of all orders.  \n"
      ],
      "metadata": {
        "id": "nNkOweZybdhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders = sc.parallelize([(1, 200), (2, 500), (3, 300), (1, 150), (2, 250)])\n",
        "\n",
        "total_per_customer = orders.reduceByKey(lambda a, b: a + b).collect()\n",
        "max_customer = orders.reduceByKey(lambda a, b: a + b).reduce(lambda a, b: a if a[1] > b[1] else b)\n",
        "total_revenue = orders.map(lambda x: x[1]).sum()\n",
        "\n",
        "print(\"Total per Customer:\", total_per_customer)\n",
        "print(\"Customer with Max Spend:\", max_customer)\n",
        "print(\"Total Revenue:\", total_revenue)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j4kKv7kZlHi",
        "outputId": "5f6575ef-a7c5-452f-d8e6-7edd552d4e84"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total per Customer: [(2, 750), (1, 350), (3, 300)]\n",
            "Customer with Max Spend: (2, 750)\n",
            "Total Revenue: 1400\n"
          ]
        }
      ]
    }
  ]
}